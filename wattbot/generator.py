"""Generate answer based on retrieved chunks"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_generator.ipynb.

# %% auto 0
__all__ = ['required_keys', 'template', 'system_prompt', 'create_context', 'fill_template', 'mk_msg', 'generate',
           'default_answer', 'replace_missing_keys', 'post_process', 'RAG']

# %% ../nbs/02_generator.ipynb 3
import os
import openai
import fastcore.all as fc
import braintrust
from dotenv import load_dotenv
from . import retriever, eda, utils

# %% ../nbs/02_generator.ipynb 9
@fc.patch
def template(self:braintrust.logger.Prompt):
    return self.prompt.messages[0].content

# %% ../nbs/02_generator.ipynb 12
@fc.patch
def system_prompt(self:braintrust.logger.Prompt): return self.prompt.messages[1].content

# %% ../nbs/02_generator.ipynb 15
def create_context(chunks):
    return "\n\n".join([retriever.Nugget(chunk, i+1) for i, chunk in enumerate(chunks)])

# %% ../nbs/02_generator.ipynb 18
@fc.patch
def fill_template(self:braintrust.logger.Prompt,  question, chunks):
    return self.build(question=question, context=create_context(chunks))['messages'][0]['content']

# %% ../nbs/02_generator.ipynb 25
def mk_msg(msg, sys): return [{"role": "system", "content": sys}, {"role": "user", "content": msg}]

# %% ../nbs/02_generator.ipynb 28
@fc.patch
def generate(self:openai.OpenAI, model, text, sys):
    return self.chat.completions.create(model=model, messages=mk_msg(text, sys), response_format={"type": "json_object"}).choices[0].message.content

# %% ../nbs/02_generator.ipynb 31
required_keys = ['answer', 'answer_value', 'answer_unit', 'ref_id', 'ref_url', 'supporting_materials', 'explanation']

# %% ../nbs/02_generator.ipynb 32
def default_answer(): return {key: 'is_blank' for key in required_keys}

# %% ../nbs/02_generator.ipynb 34
def replace_missing_keys(answer): 
    return {key: answer.get(key, 'is_blank') for key in required_keys}

# %% ../nbs/02_generator.ipynb 36
def post_process(answer):
    answer = replace_missing_keys(answer)
    if len(answer['ref_id']) == 0 or answer['ref_id'] == ['is_blank']: answer['ref_id'] = 'is_blank'
    if len(answer['ref_url']) == 0 or answer['ref_url'] == ['is_blank']: answer['ref_url'] = 'is_blank'
    return answer

# %% ../nbs/02_generator.ipynb 38
class RAG:
    def __init__(self, r, g, model='accounts/fireworks/models/gpt-oss-20b'):
        fc.store_attr()
        self.pt = braintrust.load_prompt(project="wattbot", slug="wattbot-prompt-v2")
        self.sp = self.pt.system_prompt()
        
    def answer(self, q, n_rc=10, json=True):
        rc = self.r.search(q, n=n_rc)
        pm = self.pt.fill_template(q, rc)
        try:
            ans = self.g.generate(self.model, pm, self.sp)
            if json: ans = fc.loads(ans)
        except Exception as e:
            print(e)
            ans = default_answer()
        if json: ans = post_process(ans)
        return fc.NS(ans=ans, rc=rc, pm=pm)
