<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Retriever – wattbot</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-baedc78cbf92349237790bf011c153e8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Retriever – wattbot">
<meta property="og:description" content="This repository is based on a kaggle competition named Wattbot">
<meta property="og:site_name" content="wattbot">
<meta name="twitter:title" content="Retriever – wattbot">
<meta name="twitter:description" content="This repository is based on a kaggle competition named Wattbot">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">wattbot</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./retriever.html">Retriever</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">WattBot 2025 - RAG System for Technical Document Q&amp;A</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./retriever.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Retriever</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generator</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Eval</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./submission_v1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Submissions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./submission_v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Submissions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./submission_v3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Submissions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Utils</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wattbot_exploration_solveit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploration with Solveit</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wattbot_sdk_solveit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Initial Development with Solveit</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#load-data" id="toc-load-data" class="nav-link active" data-scroll-target="#load-data">Load Data</a></li>
  <li><a href="#read-pdf" id="toc-read-pdf" class="nav-link" data-scroll-target="#read-pdf">Read pdf</a></li>
  <li><a href="#read-markdown" id="toc-read-markdown" class="nav-link" data-scroll-target="#read-markdown">Read Markdown</a></li>
  <li><a href="#total-content-size" id="toc-total-content-size" class="nav-link" data-scroll-target="#total-content-size">Total content size</a></li>
  <li><a href="#document-chunks" id="toc-document-chunks" class="nav-link" data-scroll-target="#document-chunks">Document Chunks</a></li>
  <li><a href="#markdown-chunks" id="toc-markdown-chunks" class="nav-link" data-scroll-target="#markdown-chunks">Markdown Chunks</a></li>
  <li><a href="#human-readable-chunk" id="toc-human-readable-chunk" class="nav-link" data-scroll-target="#human-readable-chunk">Human readable Chunk</a></li>
  <li><a href="#chunks-all-the-docs" id="toc-chunks-all-the-docs" class="nav-link" data-scroll-target="#chunks-all-the-docs">Chunks all the docs</a></li>
  <li><a href="#neighbour-chunks" id="toc-neighbour-chunks" class="nav-link" data-scroll-target="#neighbour-chunks">Neighbour Chunks</a></li>
  <li><a href="#lexical-search" id="toc-lexical-search" class="nav-link" data-scroll-target="#lexical-search">Lexical Search</a></li>
  <li><a href="#semantic-search" id="toc-semantic-search" class="nav-link" data-scroll-target="#semantic-search">Semantic Search</a></li>
  <li><a href="#hybrid-rerank" id="toc-hybrid-rerank" class="nav-link" data-scroll-target="#hybrid-rerank">Hybrid: Rerank</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/anubhavmaity/wattbot/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="retriever.html.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Retriever</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<div id="fd064f33-0497-4041-b8c6-67ffb20706eb" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>True</code></pre>
</div>
</div>
<section id="load-data" class="level2">
<h2 class="anchored" data-anchor-id="load-data">Load Data</h2>
<p>Loading the files - metadata - train - test</p>
<p>and viewing them</p>
<div id="c44cd115-0e78-4a8e-b03d-aea780e12be2" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>md <span class="op">=</span> eda.metadata()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>md.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">type</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">citation</th>
<th data-quarto-table-cell-role="th">url</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>amazon2023</td>
<td>report</td>
<td>2023 Amazon Sustainability Report</td>
<td>2023</td>
<td>Amazon Staff. (2023). Amazon Sustainability Re...</td>
<td>https://sustainability.aboutamazon.com/2023-am...</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>chen2024</td>
<td>paper</td>
<td>Efficient Heterogeneous Large Language Model D...</td>
<td>2024</td>
<td>Shaoyuan Chen, Wencong Xiao, Yutong Lin, Mingx...</td>
<td>https://arxiv.org/pdf/2405.01814</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>chung2025</td>
<td>paper</td>
<td>The ML.ENERGY Benchmark: Toward Automated Infe...</td>
<td>2025</td>
<td>Jae-Won Chung, Jiachen Liu, Jeff J. Ma, Ruofan...</td>
<td>https://arxiv.org/pdf/2505.06371</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>cottier2024</td>
<td>paper</td>
<td>The Rising Costs of Training Frontier AI Models</td>
<td>2024</td>
<td>Ben Cottier, Robi Rahman, Loredana Fattorini, ...</td>
<td>https://arxiv.org/pdf/2405.21015</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>dodge2022</td>
<td>paper</td>
<td>Measuring the Carbon Intensity of AI in Cloud ...</td>
<td>2022</td>
<td>Jesse Dodge, Taylor Prewitt, Remi Tachet Des C...</td>
<td>https://arxiv.org/pdf/2206.05229</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="b0f3878c-9cae-477c-a6e1-10e80cca8e32" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>qa <span class="op">=</span> eda.train()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>qa.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">question</th>
<th data-quarto-table-cell-role="th">answer</th>
<th data-quarto-table-cell-role="th">answer_value</th>
<th data-quarto-table-cell-role="th">answer_unit</th>
<th data-quarto-table-cell-role="th">ref_id</th>
<th data-quarto-table-cell-role="th">ref_url</th>
<th data-quarto-table-cell-role="th">supporting_materials</th>
<th data-quarto-table-cell-role="th">explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>q003</td>
<td>What is the name of the benchmark suite presen...</td>
<td>The ML.ENERGY Benchmark</td>
<td>ML.ENERGY Benchmark</td>
<td>is_blank</td>
<td>['chung2025']</td>
<td>['https://arxiv.org/pdf/2505.06371']</td>
<td>We present the ML.ENERGY Benchmark, a benchmar...</td>
<td>Quote</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>q009</td>
<td>What were the net CO2e emissions from training...</td>
<td>4.3 tCO2e</td>
<td>4.3</td>
<td>tCO2e</td>
<td>['patterson2021']</td>
<td>['https://arxiv.org/pdf/2104.10350']</td>
<td>"Training GShard-600B used 24 MWh and produced...</td>
<td>Quote</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>q054</td>
<td>What is the model size in gigabytes (GB) for t...</td>
<td>64.7 GB</td>
<td>64.7</td>
<td>GB</td>
<td>['chen2024']</td>
<td>['https://arxiv.org/pdf/2405.01814']</td>
<td>Table 3: Large language models used for evalua...</td>
<td>Table 3</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>q062</td>
<td>What was the total electricity consumption of ...</td>
<td>Unable to answer with confidence based on the ...</td>
<td>is_blank</td>
<td>MWh</td>
<td>is_blank</td>
<td>is_blank</td>
<td>is_blank</td>
<td>is_blank</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>q075</td>
<td>True or False: Hyperscale data centers in 2020...</td>
<td>TRUE</td>
<td>1</td>
<td>is_blank</td>
<td>['wu2021b','patterson2021']</td>
<td>['https://arxiv.org/abs/2108.06738','https://a...</td>
<td>Wu 2021, body text near Fig. 1: "…between trad...</td>
<td>The &gt;40% statement is explicit in Wu. Patterso...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="99a205ae-0474-44cb-8407-2a44299f110f" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>tst <span class="op">=</span> eda.test()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>tst.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">question</th>
<th data-quarto-table-cell-role="th">answer</th>
<th data-quarto-table-cell-role="th">answer_value</th>
<th data-quarto-table-cell-role="th">answer_unit</th>
<th data-quarto-table-cell-role="th">ref_id</th>
<th data-quarto-table-cell-role="th">ref_url</th>
<th data-quarto-table-cell-role="th">supporting_materials</th>
<th data-quarto-table-cell-role="th">explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>q001</td>
<td>What was the average increase in U.S. data cen...</td>
<td>NaN</td>
<td>NaN</td>
<td>percent</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>q002</td>
<td>In 2023, what was the estimated amount of cars...</td>
<td>NaN</td>
<td>NaN</td>
<td>cars</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>q004</td>
<td>How many data centers did AWS begin using recy...</td>
<td>NaN</td>
<td>NaN</td>
<td>data centers</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>q005</td>
<td>Since NVIDIA doesn't release the embodied carb...</td>
<td>NaN</td>
<td>NaN</td>
<td>kg/GPU</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>q006</td>
<td>By what factor was the estimated amortized tra...</td>
<td>NaN</td>
<td>NaN</td>
<td>ratio</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We have to fill up the <code>answer</code>, <code>answer_value</code>, <code>answer_unit</code>, <code>ref_id</code>, <code>ref_url</code>, <code>supporting_materials</code> and <code>explanation</code> here.</p>
<p>From the competition following values are expected</p>
<ul>
<li><p><code>answer</code>: A clear natural-language response (e.g., 1438 lbs, Water consumption, TRUE)’. If no answer is possible, use “Unable to answer with confidence based on the provided documents.”</p></li>
<li><p><code>answer_value</code>: The normalized numeric or categorical value (e.g., 1438, Water consumption, 1)</p>
<ul>
<li>If no answer is possible, use is_blank</li>
<li>Ranges should be encoded as [low,high]</li>
<li>Do not include symbols like &lt;, &gt;, ~ here. Those can be left in the clear natural language column.</li>
</ul></li>
<li><p><code>answer_unit</code>: Unit of measurement (e.g., lbs, kWh, gCO2, projects, is_blank).</p></li>
<li><p><code>ref_id</code>: One or more document IDs from metadata.csv that support the answer.</p></li>
<li><p><code>ref_url</code>: One or more URL(s) of the cited document(s).</p></li>
<li><p><code>supporting_materials</code>: Verbatim justification from the cited document (quote, table reference, figure reference, etc.).</p></li>
<li><p><code>explanation</code>: Short reasoning describing why the cited material supports the answer.</p></li>
</ul>
</section>
<section id="read-pdf" class="level2">
<h2 class="anchored" data-anchor-id="read-pdf">Read pdf</h2>
<p>I already downloaded all the pdfs, please refer the notebook <code>00_eda</code></p>
<p>We will extract the content from the pdfs here using answerdotai’s <a href="https://github.com/AnswerDotAI/ContextKit"><code>contextkit</code></a> library which uses <a href="https://github.com/py-pdf/pypdf"><code>pypdf</code></a> underneath.</p>
<p>pypdf does a decent job of text extraction from pdf but it does not preserve the layouts, table structure and reading order.</p>
<div id="5a1c911b-9793-4999-b32d-e659af081729" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>get_metadata(<span class="st">'chen2024'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>{'id': 'chen2024',
 'type': 'paper',
 'title': 'Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation',
 'year': 2024,
 'citation': 'Shaoyuan Chen, Wencong Xiao, Yutong Lin, Mingxing Zhang, Yingdi Shan, Jinlei Jiang, Kang Chen, Yongwei Wu. (2024). Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation. arXiv. https://arxiv.org/pdf/2405.01814',
 'url': 'https://arxiv.org/pdf/2405.01814'}</code></pre>
</div>
</div>
<div id="05471732-53c9-4f35-a817-3a14ef085760" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>doc_id <span class="op">=</span> <span class="st">'chen2024'</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>fc.test_eq(get_metadata(doc_id)[<span class="st">'id'</span>], doc_id)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="b851b795-34b6-49b1-86b5-a6cdf5d8f6af" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> read_doc(<span class="st">'chen2024'</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>doc.content[:<span class="dv">100</span>], doc.<span class="bu">id</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>('Efficient Heterogeneous Large Language Model Decoding\nwith Model-Attention Disaggregation\nShaoyuan C',
 'chen2024')</code></pre>
</div>
</div>
<div id="b15a7cf8-0042-4c2d-b488-77b2865e6eb4" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>doc_id<span class="op">=</span><span class="st">'chen2024'</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> read_doc(doc_id)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>fc.test_ne(<span class="bu">len</span>(doc.content), <span class="dv">0</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>fc.test_eq(doc.<span class="bu">id</span>, doc_id)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="read-markdown" class="level2">
<h2 class="anchored" data-anchor-id="read-markdown">Read Markdown</h2>
<div id="6f47ecfa-d654-422b-bdfa-d5354bd3041d" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(read_markdown(<span class="st">'chen2024'</span>).content), <span class="bu">len</span>(read_doc(<span class="st">'chen2024'</span>).content)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(75025, 69175)</code></pre>
</div>
</div>
</section>
<section id="total-content-size" class="level2">
<h2 class="anchored" data-anchor-id="total-content-size">Total content size</h2>
<div id="66986cac-95f8-4374-ac84-f8879042660c" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>fc.L(eda.metadata()[<span class="st">'id'</span>].to_list()).<span class="bu">map</span>(<span class="kw">lambda</span> x: <span class="bu">len</span>(read_doc(x).content)).<span class="bu">sum</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>2673613</code></pre>
</div>
</div>
<p>I dont think any open source models can handle that many characters in their context window as of November 2025.</p>
<p>A RAG based system will be good where we chunk the content, retrieve the relavent chunk and generate answer with those relevant chunk</p>
</section>
<section id="document-chunks" class="level2">
<h2 class="anchored" data-anchor-id="document-chunks">Document Chunks</h2>
<div id="c37bbbc4-260b-4ed3-94ed-857725d8b969" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>content, metadata <span class="op">=</span> get_content_metadata(read_doc, <span class="st">'chen2024'</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>content[:<span class="dv">100</span>], metadata</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>('Efficient Heterogeneous Large Language Model Decoding\nwith Model-Attention Disaggregation\nShaoyuan C',
 {'id': 'chen2024',
  'type': 'paper',
  'title': 'Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation',
  'year': 2024,
  'citation': 'Shaoyuan Chen, Wencong Xiao, Yutong Lin, Mingxing Zhang, Yingdi Shan, Jinlei Jiang, Kang Chen, Yongwei Wu. (2024). Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation. arXiv. https://arxiv.org/pdf/2405.01814',
  'url': 'https://arxiv.org/pdf/2405.01814'})</code></pre>
</div>
</div>
<div id="7db5a54b-494c-45a2-8050-47157f047375" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> read_doc(<span class="st">'chen2024'</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(doc.content)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>69175</code></pre>
</div>
</div>
<div id="054bff8a-0e84-4cf4-a30e-07c0b3559a20" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>chunks <span class="op">=</span> chunk_doc(<span class="st">'chen2024'</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(chunks), chunks[<span class="dv">0</span>][<span class="st">'text'</span>][<span class="op">-</span><span class="dv">200</span>:]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(50,
 ' performance and cost efficiency. Our com-\nprehensive analysis and experiments confirm the viability\nof splitting the attention computation over multiple devices.\nAlso, the communication bandwidth req')</code></pre>
</div>
</div>
<div id="97fb5749-baec-421d-b004-b9931a195d0f" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>doc_id <span class="op">=</span> <span class="st">'chen2024'</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>chunks <span class="op">=</span> chunk_doc(doc_id)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>fc.test_ne(<span class="bu">len</span>(chunks), <span class="dv">0</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>fc.test_eq(chunks[<span class="dv">0</span>].<span class="bu">id</span>, doc_id)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="33642de1-bd06-49de-9e7c-380f85a3ad42" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="dv">0</span>][<span class="st">'text'</span>][:<span class="dv">200</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'Efficient Heterogeneous Large Language Model Decoding\nwith Model-Attention Disaggregation\nShaoyuan Chen1 Wencong Xiao2 Yutong Lin1 Mingxing Zhang1 Yingdi Shan1 Jinlei Jiang1\nKang Chen1 Yongwei Wu1\n1Ts'</code></pre>
</div>
</div>
<div id="c9797d60-f846-4103-86b3-d57f44d1c071" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text='Efficient Heterogeneous Large Language Model Decoding\nwith Model-Attention Disaggregation\nShaoyuan Chen1 Wencong Xiao2 Yutong Lin1 Mingxing Zhang1 Yingdi Shan1 Jinlei Jiang1\nKang Chen1 Yongwei Wu1\n1Tsinghua University\n2ByteDance\nAbstract\nTransformer-based large language models (LLMs) exhibit\nimpressive performance in generative tasks but also intro-\nduce significant challenges in real-world serving due to in-\nefficient use of the expensive, computation-optimized accel-\nerators. Although disaggregated serving architectures have\nbeen proposed to split different phases of LLM inference, the\nefficiency of decoding phase is still low. This is caused by\nthe varying resource demands of different operators in the\ntransformer-based LLMs. Specifically, the attention operator\nis memory-intensive, exhibiting a memory access pattern that\nclashes with the strengths of modern accelerators, especially\nfor long context requests.\nTo enhance the efficiency of LLM decoding, we introduce\nmodel-attention disaggregation. This approach leverages a\ncollection of cheap, memory-optimized devices for the atten-\ntion operator while still utilizing high-end accelerators for\nother parts of the model. This heterogeneous setup ensures\nthat each component is tailored to its specific workload, max-\nimizing overall performance and cost efficiency. Our com-\nprehensive analysis and experiments confirm the viability\nof splitting the attention computation over multiple devices.\nAlso, the communication bandwidth req',
          chunk_id=0,
          id='chen2024',
          type='paper',
          title='Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation',
          year=2024,
          citation='Shaoyuan Chen, Wencong Xiao, Yutong Lin, Mingxing Zhang, Yingdi Shan, Jinlei Jiang, Kang Chen, Yongwei Wu. (2024). Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation. arXiv. https://arxiv.org/pdf/2405.01814',
          url='https://arxiv.org/pdf/2405.01814')</code></pre>
</div>
</div>
<div id="1bd66089-6eb7-417e-95b0-15f93520587a" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="op">-</span><span class="dv">1</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text='i Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\nand Luke Zettlemoyer. Opt: Open pre-trained trans-\nformer language models, 2022.\n[59] Yinmin Zhong, Shengyu Liu, Junda Chen, Jianbo Hu,\nYibo Zhu, Xuanzhe Liu, Xin Jin, and Hao Zhang. Dist-\nServe: Disaggregating prefill and decoding for goodput-\noptimized large language model serving. In 18th\nUSENIX Symposium on Operating Systems Design and\nImplementation (OSDI 24), pages 193–210, 2024.\n16',
          chunk_id=49,
          id='chen2024',
          type='paper',
          title='Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation',
          year=2024,
          citation='Shaoyuan Chen, Wencong Xiao, Yutong Lin, Mingxing Zhang, Yingdi Shan, Jinlei Jiang, Kang Chen, Yongwei Wu. (2024). Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation. arXiv. https://arxiv.org/pdf/2405.01814',
          url='https://arxiv.org/pdf/2405.01814')</code></pre>
</div>
</div>
</section>
<section id="markdown-chunks" class="level2">
<h2 class="anchored" data-anchor-id="markdown-chunks">Markdown Chunks</h2>
<div id="94d66b13-6ac2-4644-aa14-5213f51dbcd2" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>chunk_size <span class="op">=</span> <span class="dv">375</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>chunk_overlap <span class="op">=</span> <span class="dv">125</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>md_splitter <span class="op">=</span> MarkdownTextSplitter.from_tiktoken_encoder(chunk_size<span class="op">=</span>chunk_size, chunk_overlap<span class="op">=</span>chunk_overlap)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="8cad726f-7193-4de7-9fe9-2245db797440" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>md_splitter</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;langchain_text_splitters.markdown.MarkdownTextSplitter&gt;</code></pre>
</div>
</div>
<div id="dad6b6b3-d5f4-4934-84f8-0cd3f12e0941" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>doc_id <span class="op">=</span> <span class="st">'chen2024'</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>md_content <span class="op">=</span> read_markdown(doc_id).content</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>chunks <span class="op">=</span> md_splitter.split_text(md_content)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="2822511d-16eb-4169-b3cf-eba68a00a358" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="dv">0</span>][<span class="op">-</span><span class="dv">1200</span>:]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'# Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation\n\nShaoyuan Chen&lt;sup&gt;1&lt;/sup&gt; Wencong Xiao&lt;sup&gt;2&lt;/sup&gt; Yutong Lin&lt;sup&gt;1&lt;/sup&gt; Mingxing Zhang&lt;sup&gt;1&lt;/sup&gt; Yingdi Shan&lt;sup&gt;1&lt;/sup&gt; Jinlei Jiang&lt;sup&gt;1&lt;/sup&gt;  \nKang Chen&lt;sup&gt;1&lt;/sup&gt; Yongwei Wu&lt;sup&gt;1&lt;/sup&gt;\n\n&lt;sup&gt;1&lt;/sup&gt;Tsinghua University\n\n&lt;sup&gt;2&lt;/sup&gt;ByteDance\n\n## Abstract\n\nTransformer-based large language models (LLMs) exhibit impressive performance in generative tasks but also introduce significant challenges in real-world serving due to inefficient use of the expensive, computation-optimized accelerators. Although disaggregated serving architectures have been proposed to split different phases of LLM inference, the efficiency of decoding phase is still low. This is caused by the varying resource demands of different operators in the transformer-based LLMs. Specifically, the attention operator is memory-intensive, exhibiting a memory access pattern that clashes with the strengths of modern accelerators, especially for long context requests.'</code></pre>
</div>
</div>
<div id="1d1073e4-cd32-4f91-af20-8fc2e1992b45" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="dv">1</span>][:<span class="dv">1200</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'Transformer-based large language models (LLMs) exhibit impressive performance in generative tasks but also introduce significant challenges in real-world serving due to inefficient use of the expensive, computation-optimized accelerators. Although disaggregated serving architectures have been proposed to split different phases of LLM inference, the efficiency of decoding phase is still low. This is caused by the varying resource demands of different operators in the transformer-based LLMs. Specifically, the attention operator is memory-intensive, exhibiting a memory access pattern that clashes with the strengths of modern accelerators, especially for long context requests.\n\nTo enhance the efficiency of LLM decoding, we introduce model-attention disaggregation. This approach leverages a collection of cheap, memory-optimized devices for the attention operator while still utilizing high-end accelerators for other parts of the model. This heterogeneous setup ensures that each component is tailored to its specific workload, maximizing overall performance and cost efficiency. Our comprehensive analysis and experiments confirm the viability of splitting the attention computation over mult'</code></pre>
</div>
</div>
<div id="ce48a573-adf0-4eee-85f3-ba7d1a7dd8c9" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>chunks <span class="op">=</span> md_splitter.chunk_markdown(doc_id)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="ad66ba97-93a8-49de-9414-6739d2e63a9c" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="dv">0</span>].text[<span class="op">-</span><span class="dv">900</span>:]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'p&gt; Yutong Lin&lt;sup&gt;1&lt;/sup&gt; Mingxing Zhang&lt;sup&gt;1&lt;/sup&gt; Yingdi Shan&lt;sup&gt;1&lt;/sup&gt; Jinlei Jiang&lt;sup&gt;1&lt;/sup&gt;  \nKang Chen&lt;sup&gt;1&lt;/sup&gt; Yongwei Wu&lt;sup&gt;1&lt;/sup&gt;\n\n&lt;sup&gt;1&lt;/sup&gt;Tsinghua University\n\n&lt;sup&gt;2&lt;/sup&gt;ByteDance\n\n## Abstract\n\nTransformer-based large language models (LLMs) exhibit impressive performance in generative tasks but also introduce significant challenges in real-world serving due to inefficient use of the expensive, computation-optimized accelerators. Although disaggregated serving architectures have been proposed to split different phases of LLM inference, the efficiency of decoding phase is still low. This is caused by the varying resource demands of different operators in the transformer-based LLMs. Specifically, the attention operator is memory-intensive, exhibiting a memory access pattern that clashes with the strengths of modern accelerators, especially for long context requests.'</code></pre>
</div>
</div>
<div id="54f82648-a4c3-4857-ac64-53e698820819" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>chunks[<span class="dv">1</span>].text[:<span class="dv">900</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'Transformer-based large language models (LLMs) exhibit impressive performance in generative tasks but also introduce significant challenges in real-world serving due to inefficient use of the expensive, computation-optimized accelerators. Although disaggregated serving architectures have been proposed to split different phases of LLM inference, the efficiency of decoding phase is still low. This is caused by the varying resource demands of different operators in the transformer-based LLMs. Specifically, the attention operator is memory-intensive, exhibiting a memory access pattern that clashes with the strengths of modern accelerators, especially for long context requests.\n\nTo enhance the efficiency of LLM decoding, we introduce model-attention disaggregation. This approach leverages a collection of cheap, memory-optimized devices for the attention operator while still utilizing high-end'</code></pre>
</div>
</div>
</section>
<section id="human-readable-chunk" class="level2">
<h2 class="anchored" data-anchor-id="human-readable-chunk">Human readable Chunk</h2>
<p>This will help later in creating context for the prompt</p>
<div id="bcd4833b-c681-4564-8454-b534a75f0429" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Nugget(chunks[<span class="dv">42</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>### Chunk 0
            Text: ![](_page_8_Figure_0.jpeg)

(a) Request-level partition.

(b) Head-level partition.

Figure 9: Work partition methods of the attention operator.

store the KV caches and compute the attention operators. As depicted in Figure 9, the attention operators can be parallelized among memory devices in various ways. One method is to distribute different requests across different devices; an alternative strategy is to partition and distribute the attention heads, which can also be computed independently, to different devices. The head-level partitioning approach ensures a balanced workload distribution, whereas the request-level partitioning may result in load imbalance due to the differences in sequence lengths and therefore the KV cache sizes among requests. However, head-level partitioning has limited flexibility, as it requires the number of memory devices to be divisible by the number of attention heads. We opt for head-level partitioning in Lamina, which offers optimal load balancing.

## 6 Evaluation

**Testbed.** We deploy Lamina on a real heterogeneous cluster with two kinds of GPU nodes. Each node consists of either eight H100 or H20 GPUs, and each GPU is paired with a dedicated ConnectX-7 NIC via PCIe switch. The GPU nodes are interconnected with 400 Gbps RoCE network. We use H100 as compute-optimized GPUs and H20 as memory-optimized GPUs for Lamina.
            Chunk Id: 42
            Doc ID: chen2024
            Type: paper
            Title: Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation
            Year: 2024
            Citation: Shaoyuan Chen, Wencong Xiao, Yutong Lin, Mingxing Zhang, Yingdi Shan, Jinlei Jiang, Kang Chen, Yongwei Wu. (2024). Efficient Heterogeneous Large Language Model Decoding with Model-Attention Disaggregation. arXiv. https://arxiv.org/pdf/2405.01814
            URL: https://arxiv.org/pdf/2405.01814</code></pre>
</div>
</div>
</section>
<section id="chunks-all-the-docs" class="level2">
<h2 class="anchored" data-anchor-id="chunks-all-the-docs">Chunks all the docs</h2>
<div id="a9345d64-1d6e-4f55-a4ff-c8910310090e" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>all_chunks <span class="op">=</span> chunk_all(chunk_doc)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(all_chunks)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>1927</code></pre>
</div>
</div>
<div id="2b93c9c7-3cdf-422c-bdc9-c5e040844fcb" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>all_chunks[<span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text='Amazon \nSustainability \nReport\n2023 Contents\nOverview\n3 Introduction\n4 A Letter from Our Chief \nSustainability Officer\xa0\n5 How We Work\n6 Goals Summary\n7 2023 Year in Review \xa0\nEnvironment\n9 Carbon\n24 Carbon-Free Energy\n29 Packaging \n34 Waste and Circularity\n40 Water\nValue Chain\n45 Human Rights \n50 Responsible Supply Chain\n58 Sustainable Products and \nMaterials \n64 Supplier Diversity \n67 Community Impact\nPeople\n75 Employee Experience\n81 Health and Safety\n86 Inclusive Experiences\nAppendix\n94  Sustainability Reporting Topic \nAssessment\n95  Endnotes\n96 Assurance Statements \n97 Disclaimer and Forward-Looking \nStatements \nOn the cover  \nThe Baldy Mesa Solar and Storage Project (developed \nand operated by AES), located in Adelanto, California. Employees inside one of our newest office buildings in Bellevue, \nWashington.\nIntroduction 2023 Year in ReviewGoals SummaryHow We WorkCSO Letter\nAbout This Report\nThis is our sixth annual report detailing progress against \nour goals\xa0  and environmental, social, and governance \ntopics. All financial figures are reported in U.S. dollars ($), \nunless otherwise stated. The data within this report reflects \nprogress from January 1 through December 31, 2023, unless \notherwise indicated. This report includes information about \nmany business units and subsidiaries including AWS, Devices, \nFresh, Whole Foods Market, Amazon Private Brands, Twitch, \nMGM Studios, and Ring.\nOur 2023 Sustainability Report is structured into three \nmain categories: Environment',
          chunk_id=0,
          id='amazon2023',
          type='report',
          title='2023 Amazon Sustainability Report',
          year=2023,
          citation='Amazon Staff. (2023). Amazon Sustainability Report. https://sustainability.aboutamazon.com/2023-amazon-sustainability-report.pdf',
          url='https://sustainability.aboutamazon.com/2023-amazon-sustainability-report.pdf')</code></pre>
</div>
</div>
<div id="acede449-ffe2-423c-a158-c9e94ecbee7e" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>all_chunks[<span class="op">-</span><span class="dv">1</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text='\nWeidinger, L., Mellor, J., et al.: Ethical and social risks of harm from language models.\narXiv preprint arXiv:2112.04359 (2021)\n25',
          chunk_id=1926,
          id='zschache2025',
          type='paper',
          title='Comparing energy consumption and accuracy in text classification inference',
          year=2025,
          citation='Johannes Zschache, &amp; Tilman Hartwig (2025). Comparing energy consumption and accuracy in text classification inference arXiv. https://arxiv.org/pdf/2508.14170',
          url='https://arxiv.org/pdf/2508.14170 ')</code></pre>
</div>
</div>
</section>
<section id="neighbour-chunks" class="level2">
<h2 class="anchored" data-anchor-id="neighbour-chunks">Neighbour Chunks</h2>
<div id="fb825d25-b2ac-4750-a431-98ff1854bc94" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>Chunks(all_chunks).get_chunk(<span class="dv">1850</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text='ne-tune the full BlackMamba model (i.e.,\noriginal weight matrices), whereas employed QLoRA [15]\nfor parameter-efficient fine-tuning (PEFT) on Mixtral due to\nGPU memory capacity budget. For QLoRA, we target the\nMoE layers, including the routers, and set the rank of the\nLoRA modules to 16. We enable FlashAttention2 [17] during\nMixtral fine-tuning for enhanced efficiency. Moreover, we use\ngradient checkpointing [18] to save memory usage.\nDatasets. Our fine-tuning process is implemented in Py-\nTorch using the LLaMA-Factory framework [19], with a\nlearning rate of 5e-5 and 10 epochs. Both models were fine-\ntuned on two datasets focused on different tasks: common-\nsense 15k (CS) and Math 14k (MATH), which address com-\nmonsense reasoning and arithmetic reasoning respectively\n(provided by LLM-adapters [20]). The details of datasets\nare used in Table II. For evaluation, we tested the models\non GSM8K [21] for arithmetic reasoning and HE [22] for\ncommonsense reasoning. Each dataset consists of thousands\nof queries. We define a query as the concatenation of a\nprompt and its ground-truth answer, which is feed to LLMs\nfor fine-tuning.\nProfiling experiments. We evaluate the fine-tuning pro-\ncess from both software and hardware perspectives. The\nsoftware evaluation includes an end-to-end assessment of\nthe fine-tuning process and measures the performance of\nthe two models on various tasks post-fine-tuning. Using\nPyTorch, we provide essential algorithm-level information\nsuch as test accuracy, t',
          chunk_id=1850,
          id='xia2024',
          type='paper',
          title='Understanding the Performance and Estimating the Cost of LLM Fine-Tuning',
          year=2024,
          citation='Yuchen Xia, Jiho Kim, Yuhan Chen, Haojie Ye, Souvik Kundu, Cong Hao, Nishil Talati. (2024). Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. arXiv. https://arxiv.org/pdf/2408.04693',
          url='https://arxiv.org/pdf/2408.04693')</code></pre>
</div>
</div>
<div id="808bcabc-29fe-431b-9cb0-3d5968d586c0" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>left_chunk, right_chunk <span class="op">=</span> Chunks(all_chunks).get_neighbours(<span class="dv">1850</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>fc.L(left_chunk, right_chunk).attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#2) [1849,1851]</code></pre>
</div>
</div>
<div id="aaeb608a-57ba-4454-993c-4e1a6601f041" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>some_dup_chunks <span class="op">=</span> fc.L(Chunks(all_chunks).get_chunk(cid) <span class="cf">for</span> cid <span class="kw">in</span> [<span class="dv">1850</span>, <span class="dv">1851</span>, <span class="dv">1852</span>, <span class="dv">1853</span>, <span class="dv">1850</span>, <span class="dv">1851</span>, <span class="dv">1852</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="f2dfab02-890e-4761-a0ce-94bb30366315" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>Chunks.unique(some_dup_chunks).attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#4) [1850,1851,1852,1853]</code></pre>
</div>
</div>
<div id="a7cb63dc-d114-49e8-9da6-decf06e8d482" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>ans <span class="op">=</span> Chunks(all_chunks).include_neighbours(some_dup_chunks)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>ans.attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#6) [1849,1850,1851,1852,1853,1854]</code></pre>
</div>
</div>
</section>
<section id="lexical-search" class="level2">
<h2 class="anchored" data-anchor-id="lexical-search">Lexical Search</h2>
<blockquote class="blockquote">
<p>We will use BM25 here</p>
</blockquote>
<div id="98e807cd-0585-492a-9bfc-3bb480e3f2dc" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="bu">len</span>(all_chunks))</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> all_chunks[idx].text</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>all_chunks[idx]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text='easoning modes\n8 Discussion and Policy Implications\n8.1 The Critical Role of Infrastructure in AI Sustainability\nOur findings indicate that infrastructure is a crucial determinant of AI inference sustainability. While\nmodel design enhances theoretical efficiency, real-world outcomes can substantially diverge based\non deployment conditions and factors such as renewable energy usage and hardware efficiency.\nFor instance, GPT-4o mini, despite its smaller architecture, consumes approximately 20% more\nenergy than GPT-4o on long queries due to reliance on older A100 GPU nodes. Similarly, DeepSeek\nmodels highlight the profound impact of infrastructure: DeepSeek-R1 and DeepSeek-V3 deployed on\nDeepSeek’s own servers exhibit water consumption and carbon emissions nearly six times higher than\ntheir Azure-hosted counterparts. The Azure deployments benefit from better hardware, more efficient\ncooling systems, lower carbon intensity, and tighter PUE control, demonstrating that sustainability\ngains can stem as much from datacenter design as from model optimization. These observations\nunderscore that true AI sustainability will hinge on coordinated progress in hardware efficiency,\nrenewable energy sources, and infrastructure-aware deployment strategies.\n8.2 Rebound Effects and the Jevons Paradox\nAlthough large language models consume significantly less energy, water, and carbon per task than\nhuman labor [ 75], these efficiency gains do not inherently reduce overall environmental impact.\nAs p',
          chunk_id=869,
          id='jegham2025',
          type='paper',
          title='How Hungry is AI? Benchmarking Energy, Water and Carbon Footprint of LLM Inference',
          year=2025,
          citation='Nidhal Jegham, Marwan Abdelatti, Lassad Elmoubarki, Abdeltawab Hendawi (2025). How Hungry is AI? Benchmarking Energy, Water and Carbon Footprint of LLM Inference. arXiv. https://arxiv.org/pdf/2505.09598',
          url='https://arxiv.org/pdf/2505.09598')</code></pre>
</div>
</div>
<div id="446be0f3-b0c3-42fc-9a88-f7b87c6770ce" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_random_chunk(chunks): <span class="cf">return</span> all_chunks[np.random.randint(<span class="dv">0</span>, <span class="bu">len</span>(all_chunks))]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="3bfbb591-76d1-46c8-b69d-0012974b6224" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>get_random_chunk(chunks).text[:<span class="dv">100</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'eter, Compute and Data Trends in Machine Learning.https://epochai.org/data/epochdb/\nvisualization, 2'</code></pre>
</div>
</div>
<div id="af583643-f2f7-4ddf-9678-5be2cd32e1cd" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>tokenized_query <span class="op">=</span> tokenize(query)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>tokenized_query[:<span class="dv">10</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>['easoning',
 'modes',
 '8',
 'discussion',
 'and',
 'policy',
 'implications',
 '8.1',
 'the',
 'critical']</code></pre>
</div>
</div>
<div id="a75e6062-303f-40c5-b49e-574794619ffd" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>bm25 <span class="op">=</span> bm25chunks(all_chunks)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>bm25.corpus_size</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>1927</code></pre>
</div>
</div>
<div id="5660fbb8-979c-4271-b6b9-dabe9817f19e" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>bm25.get_top_n(tokenized_query, all_chunks, n<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>[namespace(text='easoning modes\n8 Discussion and Policy Implications\n8.1 The Critical Role of Infrastructure in AI Sustainability\nOur findings indicate that infrastructure is a crucial determinant of AI inference sustainability. While\nmodel design enhances theoretical efficiency, real-world outcomes can substantially diverge based\non deployment conditions and factors such as renewable energy usage and hardware efficiency.\nFor instance, GPT-4o mini, despite its smaller architecture, consumes approximately 20% more\nenergy than GPT-4o on long queries due to reliance on older A100 GPU nodes. Similarly, DeepSeek\nmodels highlight the profound impact of infrastructure: DeepSeek-R1 and DeepSeek-V3 deployed on\nDeepSeek’s own servers exhibit water consumption and carbon emissions nearly six times higher than\ntheir Azure-hosted counterparts. The Azure deployments benefit from better hardware, more efficient\ncooling systems, lower carbon intensity, and tighter PUE control, demonstrating that sustainability\ngains can stem as much from datacenter design as from model optimization. These observations\nunderscore that true AI sustainability will hinge on coordinated progress in hardware efficiency,\nrenewable energy sources, and infrastructure-aware deployment strategies.\n8.2 Rebound Effects and the Jevons Paradox\nAlthough large language models consume significantly less energy, water, and carbon per task than\nhuman labor [ 75], these efficiency gains do not inherently reduce overall environmental impact.\nAs p',
           chunk_id=869,
           id='jegham2025',
           type='paper',
           title='How Hungry is AI? Benchmarking Energy, Water and Carbon Footprint of LLM Inference',
           year=2025,
           citation='Nidhal Jegham, Marwan Abdelatti, Lassad Elmoubarki, Abdeltawab Hendawi (2025). How Hungry is AI? Benchmarking Energy, Water and Carbon Footprint of LLM Inference. arXiv. https://arxiv.org/pdf/2505.09598',
           url='https://arxiv.org/pdf/2505.09598')]</code></pre>
</div>
</div>
<div id="9e74be7b-9b97-4753-8cc3-4a85b619c487" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>ls <span class="op">=</span> LexicalSearch(all_chunks)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>lexical_res <span class="op">=</span> ls.search(query, n<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>lexical_res</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#1) [NS(text='easoning modes\n8 Discussion and Policy Implications\n8.1 The Critical Role of Infrastructure in AI Sustainability\nOur findings indicate that infrastructure is a crucial determinant of AI inference sustainability. While\nmodel design enhances theoretical efficiency, real-world outcomes can substantially diverge based\non deployment conditions and factors such as renewable energy usage and hardware efficiency.\nFor instance, GPT-4o mini, despite its smaller architecture, consumes approximately 20% more\nenergy than GPT-4o on long queries due to reliance on older A100 GPU nodes. Similarly, DeepSeek\nmodels highlight the profound impact of infrastructure: DeepSeek-R1 and DeepSeek-V3 deployed on\nDeepSeek’s own servers exhibit water consumption and carbon emissions nearly six times higher than\ntheir Azure-hosted counterparts. The Azure deployments benefit from better hardware, more efficient\ncooling systems, lower carbon intensity, and tighter PUE control, demonstrating that sustainability\ngains can stem as much from datacenter design as from model optimization. These observations\nunderscore that true AI sustainability will hinge on coordinated progress in hardware efficiency,\nrenewable energy sources, and infrastructure-aware deployment strategies.\n8.2 Rebound Effects and the Jevons Paradox\nAlthough large language models consume significantly less energy, water, and carbon per task than\nhuman labor [ 75], these efficiency gains do not inherently reduce overall environmental impact.\nAs p', chunk_id=869, id='jegham2025', type='paper', title='How Hungry is AI? Benchmarking Energy, Water and Carbon Footprint of LLM Inference', year=2025, citation='Nidhal Jegham, Marwan Abdelatti, Lassad Elmoubarki, Abdeltawab Hendawi (2025). How Hungry is AI? Benchmarking Energy, Water and Carbon Footprint of LLM Inference. arXiv. https://arxiv.org/pdf/2505.09598', url='https://arxiv.org/pdf/2505.09598')]</code></pre>
</div>
</div>
<div id="5b01929f-361c-49dc-ad95-959c89852573" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>ls <span class="op">=</span> LexicalSearch(all_chunks, neighbour_chunks<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>ls.search(query, n<span class="op">=</span><span class="dv">1</span>).attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#3) [868,869,870]</code></pre>
</div>
</div>
</section>
<section id="semantic-search" class="level2">
<h2 class="anchored" data-anchor-id="semantic-search">Semantic Search</h2>
<div id="4cc5b347-1422-4b3c-880a-99a4b5978c0e" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>embed_model <span class="op">=</span> <span class="st">'nomic-ai/nomic-embed-text-v1.5'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="465a4bbb-27ad-4d4e-a030-bde70b19d4e1" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>utils.fw().embed(embed_model, [<span class="st">'hi'</span>, <span class="st">'anubhav'</span>]).shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(2, 768)</code></pre>
</div>
</div>
<div id="9b8fa88f-6ac5-47f3-9b8a-9229f9ed8031" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> all_chunks.attrgot(<span class="st">'text'</span>)</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(texts), texts[<span class="dv">0</span>][:<span class="dv">100</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(1927,
 'Amazon \nSustainability \nReport\n2023 Contents\nOverview\n3 Introduction\n4 A Letter from Our Chief \nSust')</code></pre>
</div>
</div>
<div id="e126c4a9-b26f-4568-ba55-e1a30e9090b4" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> utils.fw().embed(embed_model, texts)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="055a438b-df15-40a5-964b-5d37d7321c24" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>embeddings.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(1927, 768)</code></pre>
</div>
</div>
<div id="5edea6fa-ba2f-4713-a794-ce71626460b7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>eda.data_path</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>Path('../data')</code></pre>
</div>
</div>
<div id="5051f1fa-8796-4ad2-8d55-0b1465bd8665" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>chunks_embeddings <span class="op">=</span> embed_chunks(all_chunks)    </span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(chunks_embeddings[<span class="dv">0</span>]), chunks_embeddings[<span class="op">-</span><span class="dv">1</span>].shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(1927, (1927, 768))</code></pre>
</div>
</div>
<div id="9a79f704-7fe4-4fd3-b382-c9cb38d468be" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>random_chunk <span class="op">=</span> get_random_chunk(all_chunks)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>random_chunk</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text=' Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding. arXiv:1810.04805 [cs.CL]\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929 (2020).\n[10] Jim Gao. 2014. Machine learning applications for data center optimization. (2014).\n[11] Michael Gillenwater. 2008. Redefining RECs—Part 1: untangling attributes and offsets. Energy Policy 36, 6 (2008), 2109–2119.\n[12] Google. 2021. Carbon free energy for Google Cloud regions. https://cloud.google.com/sustainability/region-carbon\n[13] Google. 2021. Helping you pick the greenest region for your Google Cloud resources. https://cloud.google.com/blog/topics/sustainability/pick-the-\ngoogle-cloud-region-with-the-lowest-co2\n[14] Abhishek Gupta, Camylle Lanteigne, and Sara Kingsley. 2020. SECure: A Social and Environmental Certificate for AI Systems. arXiv preprint\narXiv:2006.06217 (2020).\n[15] Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu. 2021. Chasing Carbon:\nThe Elusive Environmental Footprint of Computing. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA) .\nIEEE, 854–867.\n[16] K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dz',
          chunk_id=530,
          id='dodge2022',
          type='paper',
          title='Measuring the Carbon Intensity of AI in Cloud Instances',
          year=2022,
          citation="Jesse Dodge, Taylor Prewitt, Remi Tachet Des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, Alexandra Sasha Luccioni, Noah A. Smith, Nicole DeCario, Will Buchanan (2022). Measuring the Carbon Intensity of AI in Cloud Instances. FAccT '22. https://arxiv.org/pdf/2206.05229",
          url='https://arxiv.org/pdf/2206.05229')</code></pre>
</div>
</div>
<div id="c8c56479-efd7-4ad5-a9b3-7d2331ff0e6c" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>query_embedding <span class="op">=</span> utils.fw().embed(embed_model, random_chunk.text)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>query_embedding.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(1, 768)</code></pre>
</div>
</div>
<div id="78cb58f8-539b-4070-90ab-058cb895f286" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>all_chunks, all_embeddings <span class="op">=</span> chunks_embeddings</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cosine_similarity(query_embedding, all_embeddings)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>best_k_ind <span class="op">=</span> np.argsort(scores)[<span class="dv">0</span>].tolist()[::<span class="op">-</span><span class="dv">1</span>][:k]</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>top_k_chunks <span class="op">=</span> all_chunks[best_k_ind]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="2726a0f8-f2e6-4efe-bd18-02baeefb61d3" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>top_k_chunks[<span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>namespace(text=' Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding. arXiv:1810.04805 [cs.CL]\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929 (2020).\n[10] Jim Gao. 2014. Machine learning applications for data center optimization. (2014).\n[11] Michael Gillenwater. 2008. Redefining RECs—Part 1: untangling attributes and offsets. Energy Policy 36, 6 (2008), 2109–2119.\n[12] Google. 2021. Carbon free energy for Google Cloud regions. https://cloud.google.com/sustainability/region-carbon\n[13] Google. 2021. Helping you pick the greenest region for your Google Cloud resources. https://cloud.google.com/blog/topics/sustainability/pick-the-\ngoogle-cloud-region-with-the-lowest-co2\n[14] Abhishek Gupta, Camylle Lanteigne, and Sara Kingsley. 2020. SECure: A Social and Environmental Certificate for AI Systems. arXiv preprint\narXiv:2006.06217 (2020).\n[15] Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu. 2021. Chasing Carbon:\nThe Elusive Environmental Footprint of Computing. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA) .\nIEEE, 854–867.\n[16] K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dz',
          chunk_id=530,
          id='dodge2022',
          type='paper',
          title='Measuring the Carbon Intensity of AI in Cloud Instances',
          year=2022,
          citation="Jesse Dodge, Taylor Prewitt, Remi Tachet Des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, Alexandra Sasha Luccioni, Noah A. Smith, Nicole DeCario, Will Buchanan (2022). Measuring the Carbon Intensity of AI in Cloud Instances. FAccT '22. https://arxiv.org/pdf/2206.05229",
          url='https://arxiv.org/pdf/2206.05229')</code></pre>
</div>
</div>
<div id="cfc7c35d-b14d-4570-adb9-e8d44570933b" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> SemanticSearch(all_chunks)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>semantic_res <span class="op">=</span> ss.search(random_chunk.text, n<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(semantic_res), semantic_res[<span class="dv">0</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(1,
 namespace(text=' Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding. arXiv:1810.04805 [cs.CL]\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929 (2020).\n[10] Jim Gao. 2014. Machine learning applications for data center optimization. (2014).\n[11] Michael Gillenwater. 2008. Redefining RECs—Part 1: untangling attributes and offsets. Energy Policy 36, 6 (2008), 2109–2119.\n[12] Google. 2021. Carbon free energy for Google Cloud regions. https://cloud.google.com/sustainability/region-carbon\n[13] Google. 2021. Helping you pick the greenest region for your Google Cloud resources. https://cloud.google.com/blog/topics/sustainability/pick-the-\ngoogle-cloud-region-with-the-lowest-co2\n[14] Abhishek Gupta, Camylle Lanteigne, and Sara Kingsley. 2020. SECure: A Social and Environmental Certificate for AI Systems. arXiv preprint\narXiv:2006.06217 (2020).\n[15] Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu. 2021. Chasing Carbon:\nThe Elusive Environmental Footprint of Computing. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA) .\nIEEE, 854–867.\n[16] K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dz',
           chunk_id=530,
           id='dodge2022',
           type='paper',
           title='Measuring the Carbon Intensity of AI in Cloud Instances',
           year=2022,
           citation="Jesse Dodge, Taylor Prewitt, Remi Tachet Des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, Alexandra Sasha Luccioni, Noah A. Smith, Nicole DeCario, Will Buchanan (2022). Measuring the Carbon Intensity of AI in Cloud Instances. FAccT '22. https://arxiv.org/pdf/2206.05229",
           url='https://arxiv.org/pdf/2206.05229'))</code></pre>
</div>
</div>
<div id="602c3458-6b59-438b-b132-77b46a209982" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> SemanticSearch(all_chunks, neighbour_chunks<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>ss.search(random_chunk.text, n<span class="op">=</span><span class="dv">1</span>).attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#3) [529,530,531]</code></pre>
</div>
</div>
</section>
<section id="hybrid-rerank" class="level2">
<h2 class="anchored" data-anchor-id="hybrid-rerank">Hybrid: Rerank</h2>
<p>Here we will rerank the outputs from semantic search and lexical search using a reranker model.</p>
<p>There are other ways to mix the outputs from the above two searches like Reciprocal Rank Fusion (RRF), Linear Combination etc which you can try later</p>
<div id="aa2a6857-7a2e-4347-993f-77edc0bcc9b4" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>combined_res <span class="op">=</span> combine_chunks(semantic_res, lexical_res)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(combined_res)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>2</code></pre>
</div>
</div>
<div id="cb1bdcd2-9b5a-446f-bc90-7f7f8fd9fea2" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>combined_res.attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#2) [530,6]</code></pre>
</div>
</div>
<div id="937d7bcf-f412-442c-a468-1bad7d2e7803" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>ranker <span class="op">=</span> utils.Reranker()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="10f34206-1ab9-4624-a180-813b71278cbe" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>query[:<span class="dv">100</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'on Sustainability Report Value Chain Introduction 2023 Year in ReviewGoals SummaryHow We WorkCSO Let'</code></pre>
</div>
</div>
<div id="617255e5-084e-481f-9cc7-9ef25c317877" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>combined_res[<span class="op">-</span><span class="dv">1</span>].text[:<span class="dv">100</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'on Sustainability Report Value Chain Introduction 2023 Year in ReviewGoals SummaryHow We WorkCSO Let'</code></pre>
</div>
</div>
<div id="dd50fa94-9262-4f3b-a8ff-680dfdda5a15" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>ranker.rerank_chunks(combined_res[<span class="op">-</span><span class="dv">1</span>].text, combined_res)[<span class="dv">0</span>].text[:<span class="dv">100</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'on Sustainability Report Value Chain Introduction 2023 Year in ReviewGoals SummaryHow We WorkCSO Let'</code></pre>
</div>
</div>
<div id="7dba3ec3-1025-4319-bc0c-6521b296ea95" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>hs <span class="op">=</span> HybridSearch(ls, ss)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>chunks_res <span class="op">=</span> hs.search(combined_res[<span class="op">-</span><span class="dv">1</span>].text)</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>chunks_res[<span class="dv">0</span>].text[:<span class="dv">100</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>'23 Amazon Sustainability Report Value Chain Introduction 2023 Year in ReviewGoals SummaryHow We Work'</code></pre>
</div>
</div>
<div id="ee503c92-df4f-4aea-90bb-00c12116e24b" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>hs <span class="op">=</span> HybridSearch(ls, ss, neighbour_chunks<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>hs.search(combined_res[<span class="op">-</span><span class="dv">1</span>].text, n<span class="op">=</span><span class="dv">1</span>).attrgot(<span class="st">'chunk_id'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#3) [10,11,12]</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/anubhavmaity\.github\.io\/wattbot");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/anubhavmaity/wattbot/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>