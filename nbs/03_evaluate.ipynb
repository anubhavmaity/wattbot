{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e376f608-716f-4105-bc1c-f23994beca27",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14446dbe-94cd-4360-9bcd-4849f1278525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a75d1f-30e5-4e43-9221-241f41751ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e9bcf-cd4e-4516-a5dc-f1398b47a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import braintrust\n",
    "import ast\n",
    "import fastcore.all as fc\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from wattbot import retriever, eda, generator, evaluate, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430c4a7-46f0-43c3-aa61-c03927a3242c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcac83-a7b5-4ad7-a6d1-eeb037ab417c",
   "metadata": {},
   "source": [
    "## Score Answer Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291da1b9-19aa-4c9c-bc94-2707b5980c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def is_numeric(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39206bc0-2429-4d5e-a028-96bf01c407ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.test_eq(is_numeric(\"1.0\"), True)\n",
    "\n",
    "fc.test_eq(is_numeric(\"a\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b477c3e-25ae-4e5f-90fb-304c05ef20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def score_answer_value(predicted, expected):\n",
    "    if expected == \"is_blank\":\n",
    "        return 1.0 if predicted == \"is_blank\" else 0.0\n",
    "    \n",
    "    if isinstance(expected, str) and expected.startswith('['): expected = ast.literal_eval(expected)\n",
    "    \n",
    "    if is_numeric(expected) and is_numeric(predicted):\n",
    "        pred_num, exp_num = map(float, (predicted, expected))\n",
    "        return 1.0 if abs(pred_num - exp_num) <= abs(exp_num * 0.001) else 0.0\n",
    "    else:\n",
    "        return 1.0 if str(predicted).strip().lower() == str(expected).strip().lower() else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168226af-3e9e-4329-99f3-84d0f0a01436",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.test_eq(score_answer_value(\"is_blank\", \"is_blank\"), True)\n",
    "\n",
    "fc.test_eq(score_answer_value([\"is_blank\"], \"is_blank\"), False)\n",
    "\n",
    "fc.test_eq(score_answer_value(\"ML.ENERGY Benchmark\", \"The ML.ENERGY Benchmark\"), False)\n",
    "\n",
    "fc.test_eq(score_answer_value(\"ML.ENERGY Benchmark\", \"ML.ENERGY Benchmark\"), True)\n",
    "\n",
    "fc.test_eq(score_answer_value(\"4.3\", \"4.3\"), True)\n",
    "\n",
    "fc.test_eq(score_answer_value(\"4.3\", \"4.13\"), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ed900-e628-4cde-a521-4c02830e1b45",
   "metadata": {},
   "source": [
    "## Score Ref ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b50be8-ba7b-424d-8443-947c61fec4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def score_ref_id(predicted, expected):\n",
    "    if expected == \"is_blank\":\n",
    "        return 1.0 if predicted == \"is_blank\" else 0.0\n",
    "        \n",
    "    if isinstance(expected, str) and expected.startswith('['): expected = ast.literal_eval(expected)\n",
    "        \n",
    "    pred_set = set(predicted) if isinstance(predicted, list) else set([predicted])\n",
    "    exp_set = set(expected) if isinstance(expected, list) else set([expected])\n",
    "        \n",
    "    intersection = len(pred_set.intersection(exp_set))\n",
    "    union = len(pred_set.union(exp_set))\n",
    "        \n",
    "    return intersection / union if union > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d1750-39fe-41a8-9944-432833fe18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.test_eq(score_ref_id(\"is_blank\", \"is_blank\"), True)\n",
    "\n",
    "fc.test_eq(score_ref_id([\"is_blank\"], \"is_blank\"), False)\n",
    "\n",
    "fc.test_eq(score_ref_id([\"patterson2021\"], [\"patterson2021\"]), True)\n",
    "\n",
    "fc.test_eq(score_ref_id([\"patterson2021\"], '[\"patterson2021\"]'), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96158971-b303-4063-a3e9-9cbd9e09d75d",
   "metadata": {},
   "source": [
    "## Score is_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a365f4a-174b-4697-b242-fe548f20f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def score_is_na(predicted_answer, expected_answer):\n",
    "    na_fields = ['answer_value', 'answer_unit', 'ref_id', 'ref_url', 'supporting_materials']\n",
    "    \n",
    "    expected_is_na = expected_answer['answer_value'] == 'is_blank'\n",
    "    predicted_is_na = predicted_answer['answer_value'] == 'is_blank'\n",
    "    \n",
    "    if not expected_is_na and not predicted_is_na: return 1.0\n",
    "    \n",
    "    if expected_is_na and predicted_is_na:\n",
    "        all_fields_blank = all(predicted_answer[field] == 'is_blank' for field in na_fields)\n",
    "        return 1.0 if all_fields_blank else 0.0\n",
    "\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673feb9-4027-4b2b-bdda-1a10c0e364ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer = {\n",
    "  \"answer\": \"False\",\n",
    "  \"answer_unit\": \"is_blank\",\n",
    "  \"answer_value\": \"is_blank\",\n",
    "  \"explanation\": \"Quote\",\n",
    "  \"ref_id\": \"is_blank\",\n",
    "  \"ref_url\": \"is_blank\",\n",
    "  \"supporting_materials\": \"is_blank\"\n",
    "}\n",
    "\n",
    "expected_answer = {\n",
    "  \"answer\": \"False\",\n",
    "  \"answer_unit\": \"is_blank\",\n",
    "  \"answer_value\": \"is_blank\",\n",
    "  \"explanation\": \"Quote\",\n",
    "  \"ref_id\": \"is_blank\",\n",
    "  \"ref_url\": \"is_blank\",\n",
    "  \"supporting_materials\": \"is_blank\"\n",
    "}\n",
    "\n",
    "fc.test_eq(score_is_na(predicted_answer, expected_answer), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c9405-d870-4199-8750-83eb8cbdd66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer = {\n",
    "  \"answer\": \"False\",\n",
    "  \"answer_unit\": \"is_blank\",\n",
    "  \"answer_value\": \"0\",\n",
    "  \"explanation\": \"Quote\",\n",
    "  \"ref_id\": \"is_blank\",\n",
    "  \"ref_url\": \"is_blank\",\n",
    "  \"supporting_materials\": \"The limited availability of this data significantly reduces transparency and accountability, thereby weakening the potential for public oversight and market responses.\"\n",
    "}\n",
    "\n",
    "fc.test_eq(score_is_na(predicted_answer, expected_answer), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e021197-d472-46e6-a9dc-13138a9fe100",
   "metadata": {},
   "source": [
    "## Wattbot Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618c853-8a79-4c86-8a3b-623129288bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def calculate_wattbot_score(predicted_answer, expected_row):\n",
    "    answer_score = score_answer_value(predicted_answer['answer_value'], expected_row['answer_value'])\n",
    "    ref_score = score_ref_id(predicted_answer['ref_id'], expected_row['ref_id'])\n",
    "    na_score = score_is_na(predicted_answer, expected_row)\n",
    "    score = 0.75 * answer_score + 0.15 * ref_score + 0.10 * na_score\n",
    "    return fc.NS(score=score, answer_score=answer_score, ref_score=ref_score, na_score=na_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c4b9b-f222-470c-99c7-2b5c5636bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer = {\n",
    "    \"answer\": \"Unanswerable from the context.\",\n",
    "    \"answer_unit\": \"MWh\",\n",
    "    \"answer_value\": \"is_blank\",\n",
    "    \"explanation\": \"is_blank\",\n",
    "    \"ref_id\": \"is_blank\",\n",
    "    \"ref_url\": \"is_blank\",\n",
    "    \"supporting_materials\": \"is_blank\"\n",
    "}\n",
    "\n",
    "expected_answer = {\n",
    "    \"answer\": \"Unable to answer with confidence based on the ...\",\n",
    "    \"answer_unit\": \"MWh\",\n",
    "    \"answer_value\": \"is_blank\",\n",
    "    \"explanation\": \"is_blank\",\n",
    "    \"ref_id\": \"is_blank\",\n",
    "    \"ref_url\": \"is_blank\",\n",
    "    \"supporting_materials\": \"is_blank\"\n",
    "}\n",
    "\n",
    "ws = calculate_wattbot_score(predicted_answer, expected_answer)\n",
    "fc.test_eq(ws.na_score, 0.0)\n",
    "fc.test_eq(ws.answer_score, 1.0)\n",
    "fc.test_eq(ws.ref_score, 1.0)\n",
    "fc.test_eq(ws.score, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b1221-caa3-454d-975f-0321648b8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer = {\n",
    "    \"answer\": \"Local inference was emphasized as a sustainability measure because it reduces both network overhead and carbon footprint when deploying large language models.\",\n",
    "    \"answer_unit\": \"is_blank\",\n",
    "    \"answer_value\": \"1\",\n",
    "    \"explanation\": \"is_blank\",\n",
    "    \"ref_id\": [\"khan2025\"],\n",
    "    \"ref_url\": [\"https://arxiv.org/pdf/2504.06307\"],\n",
    "    \"supporting_materials\": \"The proposed framework tackles energy efficiency in LLM deployment through three interconnected components: local inference optimization, the selection of energy-efficient LLMs, and a comprehensive evaluation methodology.\"\n",
    "}\n",
    "\n",
    "expected_answer = {\n",
    "    \"answer\": \"Local inference was emphasized as a sustainability measure because it reduces both network overhead and carbon footprint when deploying large language models.\",\n",
    "    \"answer_unit\": \"is_blank\",\n",
    "    \"answer_value\": \"1\",\n",
    "    \"explanation\": \"is_blank\",\n",
    "    \"ref_id\": [\"khan2025\"],\n",
    "    \"ref_url\": [\"https://arxiv.org/pdf/2504.06307\"],\n",
    "    \"supporting_materials\": \"The proposed framework tackles energy efficiency in LLM deployment through three interconnected components: local inference optimization, the selection of energy-efficient LLMs, and a comprehensive evaluation methodology.\"\n",
    "}\n",
    "\n",
    "ws = calculate_wattbot_score(predicted_answer, expected_answer)\n",
    "fc.test_eq(ws.na_score, 1.0)\n",
    "fc.test_eq(ws.answer_score, 1.0)\n",
    "fc.test_eq(ws.ref_score, 1.0)\n",
    "fc.test_eq(ws.score, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8b410-4527-4511-b182-74ce21eb56d6",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88004c-3a57-4bef-b224-242cf96d589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = retriever.chunk_all(retriever.chunk_doc)\n",
    "ls = retriever.LexicalSearch(all_chunks)\n",
    "rag = generator.RAG(ls, utils.fw(), model='accounts/fireworks/models/kimi-k2p5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881235c-ad00-448f-86da-43d6194e15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def evaluate_train(rag, experiment_metadata, n_rc=10):\n",
    "    experiment_metadata['embedding_model'] = rag.r.model\n",
    "    experiment_metadata['gen_model'] = rag.model\n",
    "    experiment = braintrust.init(project=\"wattbot_v2_evaluate\", experiment=\"evaluation\", metadata=experiment_metadata)\n",
    "    result = 0\n",
    "    df = eda.train()\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\"):\n",
    "        question = row['question']\n",
    "        response = rag.answer(question, n_rc=n_rc)\n",
    "        expected = eda.get_value(row).__dict__\n",
    "        answer = response.ans\n",
    "        wattbot_score = calculate_wattbot_score(answer, expected).__dict__\n",
    "        context = list(map(lambda x: x.__dict__, response.rc))\n",
    "        prompt = response.pm\n",
    "        experiment.log(input=question, output=answer, expected=expected, scores=wattbot_score, metadata = {'context': context, 'prompt': prompt})\n",
    "        result += wattbot_score['score']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a5319-42f6-4665-a491-51e40842b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [01:35<00:00,  2.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_metadata = {\n",
    "    'pdf_extraction': 'pypdf',\n",
    "    'chunking': 'character_level',\n",
    "    'chunk_size': 1500,\n",
    "    'chunk_step': 1400,\n",
    "    'retrieval': 'lexical_search'\n",
    "}\n",
    "\n",
    "evaluate_train(rag, experiment_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746409e-6297-4f61-8f57-77e1aecf83ac",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c65a4-7914-480d-b31d-84312f55a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def create_submission(rag, experiment_metadata, n_rc=10):\n",
    "    df = eda.test()\n",
    "    questions = df['question'].to_list()\n",
    "    experiment_metadata['embedding_model'] = rag.r.model\n",
    "    experiment_metadata['gen_model'] = rag.model\n",
    "    experiment = braintrust.init(project=\"wattbot_v2_test\", experiment=\"test\", metadata=experiment_metadata)\n",
    "    for i, question in enumerate(tqdm(questions, desc=\"Answering question\")):\n",
    "        response = rag.answer(question, n_rc=n_rc)\n",
    "        answer = response.ans\n",
    "        df.loc[i, 'answer'] = str(answer['answer'])\n",
    "        df.loc[i, 'answer_value'] = str(answer['answer_value'])\n",
    "        df.loc[i, 'answer_unit'] = str(answer['answer_unit'])\n",
    "        df.loc[i, 'ref_id'] = str(answer['ref_id'])\n",
    "        df.loc[i, 'ref_url'] = str(answer['ref_url'])\n",
    "        df.loc[i, 'supporting_materials'] = str(answer['supporting_materials'])\n",
    "        df.loc[i, 'explanation'] = str(answer['explanation'])\n",
    "        context = list(map(lambda x: x.__dict__, response.rc))\n",
    "        prompt = response.pm\n",
    "        experiment.log(input=question, output=answer, scores={'score': 0}, metadata = {'context': context, 'prompt': prompt})\n",
    "        \n",
    "    df = df.fillna('is_blank')\n",
    "    df.to_csv(experiment_metadata['output_path'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3564c2-4555-4f4b-aabf-a89ed5a5e9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering question:   0%|                                                                                                                                                                    | 0/282 [00:00<?, ?it/s]/var/folders/wh/7kgzwj895cb622q6m52_0v3r0000gn/T/ipykernel_4022/2808968084.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'The total energy consumption of U.S. data centers increased by about 4% from 2010-2014' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'answer'] = str(answer['answer'])\n",
      "/var/folders/wh/7kgzwj895cb622q6m52_0v3r0000gn/T/ipykernel_4022/2808968084.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'answer_value'] = str(answer['answer_value'])\n",
      "/var/folders/wh/7kgzwj895cb622q6m52_0v3r0000gn/T/ipykernel_4022/2808968084.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['wu2021b']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'ref_id'] = str(answer['ref_id'])\n",
      "/var/folders/wh/7kgzwj895cb622q6m52_0v3r0000gn/T/ipykernel_4022/2808968084.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['https://arxiv.org/pdf/2108.06738']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'ref_url'] = str(answer['ref_url'])\n",
      "/var/folders/wh/7kgzwj895cb622q6m52_0v3r0000gn/T/ipykernel_4022/2808968084.py:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'The total energy consumption of the US data centers increased by about 4% from 2010-2014' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'supporting_materials'] = str(answer['supporting_materials'])\n",
      "/var/folders/wh/7kgzwj895cb622q6m52_0v3r0000gn/T/ipykernel_4022/2808968084.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Chunk 9 from wu2021b explicitly states that U.S. data center energy consumption increased by about 4% between 2010-2014, which directly answers the question about the average increase in electricity consumption during this period.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, 'explanation'] = str(answer['explanation'])\n",
      "Answering question: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [10:45<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "experiment_metadata['output_path'] = 'submission_v1.csv'\n",
    "create_submission(rag, experiment_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9ea2f-89c5-4463-877b-8fa0d389e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0300d-6107-4d99-be47-b8c8aeb7b1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wattbot",
   "language": "python",
   "name": "wattbot"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
