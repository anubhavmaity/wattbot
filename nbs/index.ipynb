{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6b169545-2188-4710-bf60-33f744ac9e1a",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4fc8c",
   "metadata": {},
   "source": [
    "# WattBot 2025 - RAG System for Technical Document Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbbb69c-17c3-4651-b299-27c3b9e48e36",
   "metadata": {},
   "source": [
    "`5th place` solution for the [WattBot 2025 Kaggle Competition](https://www.kaggle.com/competitions/WattBot2025) - a Retrieval-Augmented Generation (RAG) system for answering technical questions from PDF documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480fe295-f489-48ed-82f7-742333792199",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project implements a RAG pipeline that achieved 5th place on the private leaderboard (10th on public) in the WattBot 2025 competition. The system extracts information from technical PDFs, chunks and indexes the content, retrieves relevant passages, and generates answers using open-source LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6466d28-180a-4d18-a8b1-cf140680fb2b",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "- **PDF Extraction**: Extraction preserving layout, tables, and images using Datalab\n",
    "- **Hybrid Search**: Combines lexical (BM25) and semantic search with reranking\n",
    "- **Multiple LLM Support**: Integration with [Fireworks](https://fireworks.ai/) AI models (DeepSeek v3.1, Kimi k2.5, GPT-OSS 20B)\n",
    "- **Evaluation Framework**: Built-in evaluation using [Braintrust](https://braintrust.dev/) platform with WattBot scoring metrics\n",
    "- **Sliding Window Chunking**: Overlapping chunks maintain contextual continuity\n",
    "- **Neighbor Chunk Inclusion**: Retrieves adjacent chunks for better context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa15315-1546-4a9c-87f8-f0fef9e7b474",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "The pipeline consists of five main stages:\n",
    "\n",
    "1. **PDF Extraction** → Content with preserved structure\n",
    "2. **Chunking** → Sliding window approach with configurable overlap\n",
    "3. **Indexing** → BM25 lexical index + semantic embeddings (Qwen 8B)\n",
    "4. **Retrieval** → Hybrid search with Qwen 8B reranker\n",
    "5. **Generation** → JSON-formatted answers from open-source LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0a153-d532-4fc0-b376-62295709b009",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "### Clone the repository\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/anubhavmaity/wattbot.git \n",
    "cd wattbot\n",
    "```\n",
    "\n",
    "### Create and activate environment using uv\n",
    "\n",
    "```bash\n",
    "uv venv\n",
    "source .venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e6d52-bc86-4471-8792-8042c4d19166",
   "metadata": {},
   "source": [
    "### Install dependencies using pyproject.toml\n",
    "\n",
    "```bash\n",
    "uv pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4228c-8281-4fd2-a5fb-a0f873a1d667",
   "metadata": {},
   "source": [
    "### Install nbdev if not already installed\n",
    "\n",
    "```bash\n",
    "uv pip install nbdev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de4f67-134b-4a9f-9e41-20756c0d6507",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Key parameters to tune:\n",
    "\n",
    "- **PDF Extraction**: There are various tools to extract content from PDF out there like docling, pypdf, datalab etc\n",
    "- **Chunk Size**: Token/character count per chunk\n",
    "- **Overlap**: Number of overlapping tokens between chunks\n",
    "- **Retrieval Count**: Number of chunks to retrieve for lexical/semantic/hybrid\n",
    "- **Reranker Model**: Qwen 8B, Cohere etc\n",
    "- **LLM Selection**: Closed vs Open source models\n",
    "- **RRF Parameters**: Weights, window size, k constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0e610-bce9-47e3-b8e0-5e73e2c7842d",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The system uses the WattBot scoring metric:\n",
    "\n",
    "```math\n",
    "WattBot Score = 0.75 × answer_value + 0.15 × ref_id + 0.10 × is_NA\n",
    "```\n",
    "- **answer_value** (75%): Numeric answers within ±0.1% tolerance; exact categorical matches\n",
    "- **ref_id** (15%): Jaccard overlap of reference IDs\n",
    "- **is_NA** (10%): Correct identification of unanswerable questions\n",
    "\n",
    "Run evaluations and logged in Braintrust platform for detailed analysis of chunking strategies, model performance, and retrieval methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87e085-3a9d-42f0-be77-c9acef524928",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "- **Private Leaderboard**: 5th place\n",
    "- **Public Leaderboard**: 10th place\n",
    "- **Key Insights**:\n",
    "  - Lexical search (BM25) perfomed better than semantic search\n",
    "  - Markdown extraction better than text-only extraction\n",
    "  - Hybrid search with reranking provided best results\n",
    "  - Neighbor chunk increased accuracy\n",
    "  - Proprietary models (OpenAI) showed improvements but exceeded budget\n",
    "\n",
    "![Leaderboard Ranking](../images/leaderboard_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f24d2-5a2c-482e-a9ff-a09b00f13fc4",
   "metadata": {},
   "source": [
    "## Technical Highlights\n",
    "\n",
    "### PDF Extraction\n",
    "Used Datalab for markdown extraction (~$2.02 for 31 PDFs). Preserves layout, tables, and images better than pypdf or Docling.\n",
    "\n",
    "### Search Strategy\n",
    "Started with BM25 lexical search. Added Qwen 8B embeddings for semantic search. Combined both with reranking for optimal retrieval.\n",
    "\n",
    "### Prompting\n",
    "- Markdown-formatted prompts work best with open-source models\n",
    "- Explicit instructions preferred over assumptions\n",
    "- JSON output format for easy parsing\n",
    "- Tested zero-shot, few-shot, and chain-of-thought approaches\n",
    "\n",
    "### Chunking\n",
    "MarkdownTextSplitter from LangChain with sliding window overlap maintained context across chunk boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052146a2-817a-487f-95b4-dd2bf936ed88",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "Built with [nbdev](https://nbdev.fast.ai/) for literate programming approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbfc84-cd26-4be7-8a9c-3e36199194c4",
   "metadata": {},
   "source": [
    "## Lessons Learned\n",
    "\n",
    "1. Start with lexical search before jumping to vector embeddings\n",
    "2. PDF extraction quality matters more than retrieval sophistication\n",
    "3. Evaluation infrastructure is critical for iterative improvement\n",
    "4. Prompt engineering is artisanal and requires iteration\n",
    "5. Open-source models can achieve competitive results with proper tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdca55c1-20c1-42af-a7ec-3fafb60302ee",
   "metadata": {},
   "source": [
    "## Acknowledgments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3cc8cb9-d4ce-4c41-96aa-4dbb374eabc1",
   "metadata": {},
   "source": [
    "Built using [Solveit](https://solve.it.com/) for development workflow.\n",
    "\n",
    "Competition hosted by Kaggle: [WattBot 2025](https://www.kaggle.com/competitions/WattBot2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572ded2-b250-44b6-a6ba-d11bdaaf4e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
